{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /Users/andrew/git/rlmonitor/logs2\n",
      "/Users/andrew/git/rlmonitor/logs2 agent\n",
      "/Users/andrew/git/rlmonitor/logs2 agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from skimage.transform import rescale\n",
    "\n",
    "import tensorflow as tf\n",
    "from baselines.common.tf_util import load_variables\n",
    "from baselines import deepq\n",
    "from baselines.run import train\n",
    "import gym\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from gym_recorder.recorder import Recorder\n",
    "from gym_recorder.utils import shortlist_operations, get_activations\n",
    "from gym_recorder.perturb import perturb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_type: atari\n",
      "Training deepq on atari:EnduroNoFrameskip-v4 with arguments \n",
      "{'network': 'conv_only', 'lr': 0.0001, 'buffer_size': 10000, 'exploration_fraction': 0.1, 'exploration_final_eps': 0.01, 'train_freq': 4, 'learning_starts': 10000, 'target_network_update_freq': 1000, 'gamma': 0.99, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'checkpoint_freq': 10000, 'checkpoint_path': None, 'dueling': True, 'load_path': '../models/enduro_0_dqn'}\n",
      "Loaded model from ../models/enduro_0_dqn\n"
     ]
    }
   ],
   "source": [
    "arguments = dict(alg='deepq',\n",
    "            env='PongNoFrameskip-v4', \n",
    "            gamestate=None,\n",
    "            network=None,\n",
    "            num_env=None, \n",
    "            num_timesteps=0.0, \n",
    "            play=True, \n",
    "            reward_scale=1.0, \n",
    "            save_path=None, \n",
    "            seed=None)\n",
    "\n",
    "extra_arguments = dict(load_path='../../models/pong_1e6_dqn')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "for key in arguments:\n",
    "    parser.add_argument(f'--{key}')\n",
    "\n",
    "extra_parser = argparse.ArgumentParser()\n",
    "for key in extra_arguments:\n",
    "    extra_parser.add_argument(f'--{key}')\n",
    "\n",
    "args = parser.parse_args('')\n",
    "extra_args = parser.parse_args('')\n",
    "\n",
    "args.alg = 'deepq'\n",
    "args.env='EnduroNoFrameskip-v4'\n",
    "args.gamestate=None\n",
    "args.network=None\n",
    "args.num_env=None\n",
    "args.num_timesteps=0.0\n",
    "args.play=True\n",
    "args.reward_scale=1.0\n",
    "args.save_path=None\n",
    "args.seed=None\n",
    "\n",
    "extra_args = dict(load_path='../models/enduro_0_dqn')\n",
    "\n",
    "model, env = train(args, extra_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "session = tf.get_default_session()\n",
    "n_episodes = 1\n",
    "operations = {'q_values': 'deepq/q_func/action_value/fully_connected_1/MatMul',\n",
    "              '2nd_to_last': 'deepq_1/q_func/convnet/Conv_2/Relu'}\n",
    "input1 = session.graph.get_operation_by_name('deepq/observation').outputs[0]\n",
    "input2 = session.graph.get_operation_by_name('deepq_1/obs_t').outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-31 16:18:14,811 Start recording for None steps or 1 episodes with a sample modulo of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting video with frame shape: (210, 160, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-31 16:18:16,111 Step 100 in episode 1\n",
      "2019-01-31 16:18:17,436 Step 200 in episode 1\n",
      "2019-01-31 16:18:18,564 Step 300 in episode 1\n",
      "2019-01-31 16:18:19,610 Step 400 in episode 1\n",
      "2019-01-31 16:18:20,677 Step 500 in episode 1\n",
      "2019-01-31 16:18:21,864 Step 600 in episode 1\n",
      "2019-01-31 16:18:23,237 Step 700 in episode 1\n",
      "2019-01-31 16:18:24,430 Step 800 in episode 1\n",
      "2019-01-31 16:18:25,627 Step 900 in episode 1\n",
      "2019-01-31 16:18:26,932 Step 1000 in episode 1\n",
      "2019-01-31 16:18:28,042 Step 1100 in episode 1\n",
      "2019-01-31 16:18:29,156 Step 1200 in episode 1\n",
      "2019-01-31 16:18:30,270 Step 1300 in episode 1\n",
      "2019-01-31 16:18:31,521 Step 1400 in episode 1\n",
      "2019-01-31 16:18:32,664 Step 1500 in episode 1\n",
      "2019-01-31 16:18:33,789 Step 1600 in episode 1\n",
      "2019-01-31 16:18:34,902 Step 1700 in episode 1\n",
      "2019-01-31 16:18:36,057 Step 1800 in episode 1\n",
      "2019-01-31 16:18:37,178 Step 1900 in episode 1\n",
      "2019-01-31 16:18:38,327 Step 2000 in episode 1\n",
      "2019-01-31 16:18:39,476 Step 2100 in episode 1\n",
      "2019-01-31 16:18:40,603 Step 2200 in episode 1\n",
      "2019-01-31 16:18:41,699 Step 2300 in episode 1\n",
      "2019-01-31 16:18:42,791 Step 2400 in episode 1\n",
      "2019-01-31 16:18:43,947 Step 2500 in episode 1\n",
      "2019-01-31 16:18:45,051 Step 2600 in episode 1\n",
      "2019-01-31 16:18:46,152 Step 2700 in episode 1\n",
      "2019-01-31 16:18:47,479 Step 2800 in episode 1\n",
      "2019-01-31 16:18:48,561 Step 2900 in episode 1\n",
      "2019-01-31 16:18:49,688 Step 3000 in episode 1\n",
      "2019-01-31 16:18:50,740 Step 3100 in episode 1\n",
      "2019-01-31 16:18:52,200 Step 3200 in episode 1\n",
      "2019-01-31 16:18:53,359 Step 3300 in episode 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished recording episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-31 16:18:53,738 Done recording 3320 steps with a sample modulo of 1 in 38.9 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record gameplay\n",
    "recorder = Recorder(act=model, env=env, operations=operations)\n",
    "recorder.record(\n",
    "    session=session,\n",
    "    feed_operations=([input1, input2]), \n",
    "    max_episodes=1,\n",
    "#     max_steps=3000,\n",
    "    sample_modulo=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrew/git/fabian/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3320"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recorder.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.observations = [ob for ix, ob in enumerate(recorder.observations) if (ix%5==0) and (ix<500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../saliencies/00000000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6776ff8de4f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../saliencies/{:08}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/p36/lib/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s is a boolean image: setting True to 1 and False to 0'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imsave'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36/lib/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, format_str, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray_to_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../saliencies/00000000.png'"
     ]
    }
   ],
   "source": [
    "from skimage.io import imsave\n",
    "for ix, frame in enumerate(recorder.frames[0:10]):\n",
    "    filename = '../saliencies/a{:08}.png'.format(ix)\n",
    "    imsave(filename, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 4\n",
    "recorder.get_saliencies(session=session,\n",
    "                        operation_name='deepq/q_func/action_value/fully_connected_1/MatMul',\n",
    "                        feed_operations=[input1, input2],\n",
    "                        step_size=step_size,\n",
    "                        mode='clipping'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! open .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "for ix, frame in enumerate(recorder.saliencies):\n",
    "    filename = '../saliencies_random/{:08}.png'.format(ix)\n",
    "    imsave(filename, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for heatmap in recorder.saliencies:\n",
    "    plt.figure(figsize=(heatmap.shape[0]/20, heatmap.shape[1]/20))\n",
    "    plt.imshow(heatmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for heatmap in recorder.saliencies:\n",
    "    plt.figure(figsize=(heatmap.shape[0]/15, heatmap.shape[1]/15))\n",
    "    plt.imshow(heatmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recorder.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recorder.episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.episode_rewards = [ob for ix, ob in enumerate(recorder.episode_rewards) if (ix%5==0) and (ix<500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recorder.observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'n_steps': recorder.n_steps,\n",
    "           'episode_reward': recorder.episode_rewards}\n",
    "n_frames = 3000 #len(recorder.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = TSNE()\n",
    "activations = recorder.activations['2nd_to_last']\n",
    "vectors = [np.squeeze(array)[:,:,0].flatten() for array in activations]\n",
    "embedding = embedder.fit_transform(vectors)\n",
    "x, y = zip(*embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in mapping:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(x, y, c=mapping[variable], alpha=0.3)\n",
    "    plt.colorbar()\n",
    "    plt.title(f't-SNE embeddings of {n_frames} frames\\ncolored by {variable}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p36]",
   "language": "python",
   "name": "conda-env-p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
